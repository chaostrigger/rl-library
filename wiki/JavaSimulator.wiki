#summary This wiki page will document our progress on a Java Keep-away simulator.
#labels Featured,Phase-Design
= Introduction =

Basically, we have the simulator in Java that is a direct as possible port of the soccer code from Mat Buckland's book, Progamming Game AI by Example.

That has come along quite well, and we have working code as a RL-Glue domain with an RL-Viz visualizer.

= Challenges and TODOS =

Here are some facts about Austin Robocup Keep-away.  For each, we should either implement it, or change it and document it.

  * Bounds: Need to have a square that is the field, and if the ball goes out, episode over
  * Keeper-control: We can easily make it so that either one keeper is learning or they all are learning using the same agent.  What do we prefer?  I think having them all learn.
  * Game ends when takers have control of ball for a set period of time.  How much?
  * Takers all start in bottom left
  * Keepers are randomly assigned to the top 3 corners, rest of keepers go to middle
  * Top-left keeper starts with the ball
  * 
- 

= Done =

==Keep-away is a semi-mdp but RL-Viz only draws on RL_step
We solved this problem by making the Keep-away domain store a history of recent states and then send the whole list over to RL-Viz when it wants new information.  RL-Viz can then play back the intermediate simulator steps between agent actions.  This gives us the illusion of a continuously running RL-Viz simulation, but we're only really getting information at keeper decision points. 